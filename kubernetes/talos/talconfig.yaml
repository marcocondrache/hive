---
clusterName: &clusterName hive

endpoint: https://k8s.hive.internal:6443

# renovate: datasource=docker depName=ghcr.io/siderolabs/installer
talosVersion: v1.10.4
# renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet
kubernetesVersion: v1.33.2

clusterPodNets:
  - "10.42.0.0/16"

clusterSvcNets:
  - "10.43.0.0/16"

additionalApiServerCertSans: &sans
  - k8s.hive.internal
  - &vip 10.0.30.20
  - 127.0.0.1

additionalMachineCertSans: *sans

cniConfig:
  name: none

nodes:
  - hostname: queen.hive.internal # queen leadership
    ipAddress: 10.0.30.21
    installDisk: /dev/mmcblk0 # eMMC
    controlPlane: true

    networkInterfaces:
      - interface: end0
        dhcp: true
        vip:
          ip: *vip
        vlans:
          - &lab
            vlanId: 30
            dhcp: false

  # missing hardware
  # - hostname: royal-jelly.hive.internal # sustenance
  #   ipAddress: 192.168.0.52
  #   controlPlane: true
  #   installDisk: /dev/mmcblk0 # eMMC
  #   networkInterfaces:
  #     - interface: end0
  #       dhcp: true

  # missing hardware
  # - hostname: royal-guard.hive.internal # protection
  #   ipAddress: 192.168.0.53
  #   controlPlane: true
  #   installDisk: /dev/mmcblk0 # eMMC
  #   networkInterfaces:
  #     - interface: end0
  #       dhcp: true
  #       vip:
  #         ip: *vip

  - hostname: forager.hive.internal
    ipAddress: 10.0.30.29
    installDisk: /dev/mmcblk0 # eMMC
    networkInterfaces:
      - interface: end0
        dhcp: true
        vlans:
          - *lab

patches:
  - "@./patches/common/machine-files.yaml"
  - "@./patches/common/machine-kubelet.yaml"
  - "@./patches/common/machine-network.yaml"
  - "@./patches/common/machine-features.yaml"
  - "@./patches/common/machine-sysctls.yaml"

controlPlane:
  nodeLabels: &nodeLabels
    topology.kubernetes.io/region: *clusterName
    topology.kubernetes.io/zone: m

  extraManifests:
    - "@./manifests/watchdog.yaml"

  kernelModules: &turingrk1-kernelModules
    - name: gpu-sched
    - name: panfrost

  machineSpec: &turingrk1-machineSpec
    mode: metal
    arch: arm64
    secureboot: false
    useUKI: false
    bootMethod: disk-image
    imageSuffix: raw.xz

  schematic: &turingrk1-schematic
    overlay:
      name: turingrk1
      image: siderolabs/sbc-rockchip
    customization:
      extraKernelArgs:
        - -selinux
        - apparmor=0
        - security=none
        - mitigations=off
        - talos.auditd.disabled=1
        - rockchip_drm.dmc_enable=1
      systemExtensions:
        officialExtensions:
          - siderolabs/panfrost
          - siderolabs/iscsi-tools
          - siderolabs/util-linux-tools

  volumes: &turingrk1-volumes
    - name: EPHEMERAL
      provisioning:
        diskSelector:
          match: disk.transport == "nvme"
        maxSize: 100GiB

  userVolumes: &turingrk1-userVolumes
    - name: data
      provisioning:
        diskSelector:
          match: disk.transport == "nvme"
        minSize: 100GiB
        grow: true

  patches:
    - |-
      - op: remove
        path: /cluster/apiServer/admissionControl

    - |-
      cluster:
        apiServer:
          extraArgs:
            runtime-config: admissionregistration.k8s.io/v1alpha1=true
            feature-gates: MutatingAdmissionPolicy=true

    - "@./patches/controlplane/cluster.yaml"
    - "@./patches/controlplane/machine-features.yaml"

worker:
  nodeLabels: *nodeLabels

  extraManifests:
    - "@./manifests/watchdog.yaml"

  kernelModules: *turingrk1-kernelModules

  machineSpec: *turingrk1-machineSpec
  schematic: *turingrk1-schematic

  volumes: *turingrk1-volumes
  userVolumes: *turingrk1-userVolumes
